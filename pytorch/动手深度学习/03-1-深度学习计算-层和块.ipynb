{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1065, -0.1907,  0.1071,  0.0712, -0.0533, -0.0039, -0.1149, -0.2018,\n",
       "         -0.3443, -0.1287],\n",
       "        [-0.1307, -0.0910, -0.0081,  0.0692, -0.1625,  0.0409, -0.1012, -0.1514,\n",
       "         -0.2303, -0.1841]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在下面的代码片段中，我们从零开始编写一个块。 \n",
    "# 它包含一个多层感知机，其具有256个隐藏单元的隐藏层和一个10维输出层。 \n",
    "# 注意，下面的MLP类继承了表示块的类。 我们的实现只需要提供我们自己的构造函数（Python中的__init__函数）和前向传播函数。\n",
    "class MLP(nn.Module):\n",
    "    # 用模型声明参数层\n",
    "    def __init__(self):\n",
    "        # 调用MLP的父类Block的构造函数来执行必要的初始化。 这样，在类实例化时还可以指定其他函数参数，例如模型参数的访问。\n",
    "        super().__init__()\n",
    "        # 隐藏层\n",
    "        self.hidden = nn.Linear(20,256)\n",
    "        self.out = nn.Linear(256,10)\n",
    "        \n",
    "    # 定义模型的前向传播,即如何根据输入x返回所需的模型输出\n",
    "    def forward(self,X):\n",
    "        # 通过激活函数ReLU处理隐藏层的输出\n",
    "        return self.out(F.relu(self.hidden(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1300, -0.0376,  0.0751, -0.0770,  0.0246, -0.0219, -0.1027, -0.1690,\n",
       "          0.0028, -0.1055],\n",
       "        [-0.2843, -0.0708,  0.1549,  0.0617, -0.0703,  0.0210, -0.1860, -0.3221,\n",
       "          0.0476, -0.1954]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顺序块\n",
    "class MySequential(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super(MySequential, self).__init__()\n",
    "        for block in args:\n",
    "            # 这里，block是Module子类的一个实例，我们把它保存在'Module'类的成员变量_children中。 \n",
    "            # 这样，block就成为了MySequential类对象的一个模块，从而MySequential的参数就包括了block中的所有需要训练的参数。\n",
    "            self._modules[block] = block\n",
    "\n",
    "    def forward(self, X):\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0387, -0.1209, -0.1194,  0.1890, -0.3328,  0.4535, -0.1412,  0.1038,\n",
       "          0.1036,  0.1111],\n",
       "        [-0.0550,  0.0205, -0.0841,  0.1580, -0.2243,  0.2520, -0.0853,  0.0992,\n",
       "          0.0186,  0.0153]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 下面，我们用MySequential类来实现前面描述的MLP类\n",
    "net = MySequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1105, -0.1595,  0.0608,  0.0813,  0.0857,  0.0167, -0.1526,  0.0688,\n",
       "          0.1065, -0.0058],\n",
       "        [-0.1836, -0.1531,  0.1073,  0.0129,  0.0446, -0.1036, -0.0503, -0.0502,\n",
       "          0.0540, -0.1891]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在这个例子中，我们提供了一个简化的实现。\n",
    "# 由于Sequential类本质上是一个OrderedDict容器，我们可以用它的add_module函数来添加一个块。\n",
    "# 这在实现MySequential类时非常有用。\n",
    "net = nn.Sequential()\n",
    "net.add_module('hidden', nn.Linear(20, 256))\n",
    "net.add_module('relu', nn.ReLU())\n",
    "net.add_module('output', nn.Linear(256, 10))\n",
    "net(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
